---
title: "Performance"
author: 
  - "Martin Arnold"
  - "Alexander Gerber"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    seal: false
    lib_dir: libs
    css: ["../xaringan_files/xaringan-themer.css", "../xaringan_files/custom.css"]
    nature:
      beforeInit: ../xaringan_files/macros.js
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    includes:
      after_body: ../xaringan_files/terminal_highlight.html
---

```{r setup, include=FALSE}
options(htmltools.dir.version = F)
knitr::opts_chunk$set(warning = F, message = F)
```

```{r xaringan-themer, include=FALSE}
# solarized_dark(
#   code_font_family = "Fira Code",
#   code_font_url    = "https://cdn.rawgit.com/tonsky/FiraCode/1.204/distr/fira_code.css"
# )
# library(xaringanthemer)
# 
# mono_accent(
#     base_color           = "#09017F",
#     header_font_google   = google_font("Roboto", "700"),
#     text_font_google     = google_font("Roboto Condensed"),
#     code_highlight_color = "#D2B6E8",
#     code_font_family     = "Fira Code",
#     code_font_url        = "https://cdn.rawgit.com/tonsky/FiraCode/1.204/distr/fira_code.css"
#     )
```

```{r, include=FALSE}
library(microbenchmark)
```

class: top, left

### Performance &mdash; Overview

- Measuring Performance: Profiling and Microbenchmarking

- (Why) is R slow?

- Improving Performance

- Speeding things up using Rcpp

- Parallelization

---
class: inverse, middle, left

background-image: url(img/road.jpg)
background-size: cover

### Measuring Performance

#### *Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered.*

#### — Donald Knuth (famous american computer scientist) .

---
## Prerequisites

Before trying to make code run faster it is necessary to understand what is making it slow. `r emo::ji('snail')`


**Profiling** means measuring run time of our code line-by-line using realistic inputs in order to identify *bottlenecks*.

After identifying bottlenecks we experiment with equvalent alternatives of code and find the fastest using a **microbenchmark**.

We will use the packages `profvis` and `bench` for profiling and benchmarking. Please make sure they are installed by checking whether the following code chunk executes without issues.

```{r, echo=T, eval=F}
library(profvis)
library(bench)
```

---
class: inverse, middle, left

### Profiling

#### *It’s tempting to think you just know where the bottlenecks in your code are. I mean, after all, you write it! But trust me, I can’t tell you how many times I’ve been surprised at where exactly my code is spending all its time. The reality is that profiling is better than guessing.*

#### — Roger D. Peng

---
### Profiling - `utils::Rprof()`

`Rprof()` is a build-in *sampling profiler*. It keeps track of the *function call stack* at regularly sampled intervals.

- The function call stack is a record of the function currently executing, the function that called the function, and so on (from right to left)

- The default time interval between sampling is 0.02 seconds. If the profiled code executes faster you need to pass an appropriate sampling time to the arguement `interval`.

- The output of `Rprof()` is a complete listing of the function call stack at every sampling iteration (which, on its own, is often not very informative) which is printed to a binary file in the current working directory

- Note: results are *stochastic* &mdash; we never run a function twice under the same conditions (memory usage, CPU load etc.) 

---
### `utils::Rprof()`

**Example: profiling a call of `replicate()`**

```{r, eval = F, cache=TRUE}
tmp <- tempfile()

Rprof(tmp, interval = 0.1)       # start the profiler
replicate(5, mean(rnorm(1e6)))
Rprof(NULL)                      # stop profiling

writeLines(readLines(tmp))
```
```{r, echo=FALSE}
cat('
sample.interval=100000
"rnorm" "mean" "FUN" "lapply" "sapply" "replicate" 
"rnorm" "mean" "FUN" "lapply" "sapply" "replicate" 
"rnorm" "mean" "FUN" "lapply" "sapply" "replicate" 
')
```

So `rnorm()` is six levels deep in the call stack and it seems that R spends most of time evaluating `rnorm(1e6)` and the code takes ~ 0.3 seconds to run.

---
### `utils::Rprof()`

A more useful output is produced by `utils::summaryRprof()`. 

By appending `$by.total` we get the time spend in each function by the total run time. 

**Example: Profiling a call of `replicate()`**

```{r, eval=F}
summaryRprof(tmp)$by.total
```

```{r, echo = F}
cat('
             total.time total.pct self.time self.pct
"rnorm"            0.3       100       0.3      100
"FUN"              0.3       100       0.0        0
"lapply"           0.3       100       0.0        0
"mean"             0.3       100       0.0        0
"replicate"        0.3       100       0.0        0
"sapply"           0.3       100       0.0        0
')
```

---
### `utils::Rprof()`

By appending `$by.self` the results are adjusted for the time to run functions above the current function in the call stack.

**Example: profiling a call of `replicate()`**
```{r, eval=F}
summaryRprof(tmp)$by.self
```
```{r, echo = F}
cat('
       self.time self.pct total.time total.pct
"rnorm"       0.3      100        0.3       100
')
```

As expected, the random number generation takes approx. 100% of the total computation time.

---
### Visualising profiles: `profvis::profvis()`
**Example: profiling nested functions**

```{r}
# define some nested example functions
f <- function() {
  pause(0.1)
  g()
  h()
}

g <- function() {
  pause(0.1)
  h()
}

h <- function() {
  pause(0.1)
}
```

(We use `profvis::pause()` because the time spend in `base::sys.sleep()` is not measured as computing time.)

---
### Visualising profiles: `profvis::profvis()`
**Example: profiling nested functions**

Visualisation using `profvis()` works best when the code is sourced from an .R-script

```{r, eval=FALSE}
# source f(), g(), h() form R script
source("codes/profiling-example.R")

# visualise profiling results
profvis(f())
```

After profiling, `profvis()` opens an interactive HTML window will *RStudio* which lets you explore the results.

The interface provided by `profvis()` connects the profiling data back to the source code. This makes it easier to build up a 'mental' model of what you need to change.

---
background-image: url(img/profiling.png)
background-position: 50% 85%
background-size: 600px

### Visualising profiles: `profvis::profvis()`

---
### Visualising profiles: `profvis::profvis()`

The top pane 

- displays bar plots of running times and memory allocations with the latter being no issue here (why?)

- provides a good overall feel for bottlenecks but is quite imprecise about the *cause*

  `h()` is not significanly slower than `g()`: `h()` is reported to take 150 ms (twice as long as `g()`) because it is called two times.


The bottom pane shows a *flame graph* of the full call stack. The full sequence confirms that

 - `h()` is called from two different places (once by `g()` and once by `f()`)

 - the execution time of `h()` is roughly the same in each call.
 
Mousing over a cell in the function stack indicates the corresponding line in the source code.

---
background-image: url(img/profiling_data_tab.png)
background-position: 50% 85%
background-size: 500px

### Visualising profiles: `profvis::profvis()`

The data tab provides a tree-based representation of the top pane. <br> (useful for analysing more complicated components of the code)

---
### Visualising profiles: `profvis::profvis()`
**Example: profiling linear regression**

```{r, eval=FALSE}
profvis({
  
  dat <- data.frame(
    x = rnorm(5e4),
    y = rnorm(5e4)
  )

  plot(x ~ y, data = dat)
  m <- lm(x ~ y, data = dat)
  abline(m, col = "red")

})
```

---
background-image: url(img/profiling_regression_1.png)
background-position: 50% 80%
background-size: 650px
### Visualising profiles: `profvis::profvis()`
**Example: profiling linear regression**

---
background-image: url(img/profiling_regression_2.png)
background-position: 50% 80%
background-size: 650px
### Visualising profiles: `profvis::profvis()`
**Example: profiling linear regression**


---
### Memory Profiling

**Example: extensive garbage collection**

The following code generates a large number of short-lived objects by *copy-on-modify*.

```{r, eval=F}
profvis({
  
  x <- integer()
  
  for (i in 1:1e4) {
    x <- c(x, i)
  }
  
})
```

---
background-image: url(img/profiling_gc.png)
background-position: 50% 70%
background-size: 650px

### Memory Profiling

It looks like R spends most of the time modifying the data in-place, but that’s not actually what’s happening internally.

---
### Memory Profiling

What is going on?

- The memory column indicates that large amounts of memory are being allocated (right bar) and freed (left bar)

  Reasons: 
  
  1. A new memory object is generated by modifying a copy of the 'old' `x` which is then reassigned to `x` in each iteration
  
  2. Garbage collection (GC) automatically frees memory by deleting no more required objects

- While `c()` runs for a total of 170 ms, a considerable amount of this time is due to garbage collection (`<GC>`)

When you see the garbage collector taking up a lot of time, you can often come up with a more efficient alternative.

---
### Memory Profiling

Sometimes code statements seem fairly innocent but are very inefficient both when it comes to memory and speed.

**Example: coercion to another type**

```{r, eval=F, }
profvis({
  x <- matrix(nrow = 1e4, ncol = 1e4)
  x[1, 1] <- 0
  x[1:3, 1:3] 
})
```

---
background-image: url(img/profiling_coercion.png)
background-position: 50% 90%
background-size: 650px
### Memory Profiling
**Example: coercion to another type**

Can you explain why execution of the third line needs 762.9MB memory?

---
### Memory Profiling
**Example: coercion to another type**
```{r, cache=T}
p <- profmem::profmem({
  x <- matrix(nrow = 1e4, ncol = 1e4)
  x[1, 1] <- 0
  x[1:3, 1:3]  
})

print(p, expr = F)
```

---
### Memory Profiling

**Example: coercion to another type**

What is going on?

The code seems fairly innocent, but it turns out that it is very inefficient - both when it comes to memory and speed:

- `x` is initialized with type `logical` (it is filled with `NA`s) and thus cannot contain numeric values.

- `x[1, 1] <- 0` internally coerces `x` to a `numeric` matrix before assigning `0` to the (1,1) element which is quite costly: initializing `x` was more than twice as fast!

Especially if a large number of computations need to be performed, coercion should be avoided wherever possible!

---
### Profiling &mdash; some notes and hints

- C/C++ (or other compiled) code cannot be profiled

- We also cannot profile what happens *inside* primitive functions, e.g., `sum()` and `sqrt()` (these functions are written in C or Fortran).

  We thus cannot use profiling to see wether the code is slow due because something further down the call stack is slow.
  
**Example: primitive functions**
  
```{r, eval=F}
profvis({
  sqrt(sum(abs(rnorm(sum(1e6)))))
  })
```

- Profiling is just another reason to **break your code into functions** so that the profiler can give useful information about where time is being spent

---
class: inverse, left, top
background-image: url(img/road.jpg)
background-size: cover
# Microbenchmarking

---
### What is a Microbenchmark?

*A microbenchmark is a program designed to test a very small snippets of code for a specific task. Microbenchmarks are always artificial and they are not intended to represent normal use.*

- We usually speak of milliseconds (ms), microseconds (µs), or nanoseconds (ns) here. 

- Important: microbenchmarks can rarely be generalised to 'real' code: the observed differences in microbenchmarks will typically be dominated by **higher-order effects** in real code.

  Think of it this way:
  
  A deep understanding of quantum physics is not very helpful when baking cookies.
  
- There are several R packages for microbenchmarking. We will rely on the `bench` package by Hester (2018) which currently has the most accurate timer function.

---
### Microbenchmarking &mdash; the `bench` package

- `bench` is part of the `tidyerse`. It uses the highest precision APIs available for the common operating system (often nanoseconds-level!)

- `mark()` is the working horse of the `bench` package and measures both memory allocation and computation time.

- By default, a human-readable statistical summary on the distributions of memory load and timings based on 1e4 iterations is returned which also reports on garbage collections

- Benchmarking across a grid of input values with `bench::press()` is possible

- The package also has methods for neat visualization of the results using `ggplot2::autoplot()` (default plot type is [beeswarm](https://flowingdata.com/2016/09/08/beeswarm-plot-in-r-to-show-distributions/)) 

---
### Microbenchmarking &mdash; `bench::mark()`

**Example: "the fastest square root"**

```{r, eval=1:5}
x <- runif(100)
(lb <- bench::mark(
  sqrt(x),
  x ^ 0.5
))

```

```{r, eval=F, warning=F, message=F}
plot(lb)
```

---
### Microbenchmarking &mdash; `bench::mark()`

**Example: "the fastest square root"**

```{r, echo=F, fig.width=14, fig.height=8.5}
plot(lb)
```

---
### Microbenchmarking &mdash; `bench::mark()`

**Example: non-equivalent code**

```{r, eval=F}
set.seed(42)

dat <- data.frame(
  x = runif(10000, 1, 1000),
  y = runif(10000, 1, 1000))

bench::mark(
  dat[dat$x > 500, ],
  dat[which(dat$x > 499), ],
  subset(dat, x > 500))
```

```{r, echo=FALSE}
cat('
Error: Each result must equal the first result:
  `dat$x > 500` does not equal `which(dat$x > 499)` Each result must 
  equal the first result:
  `` does not equal ``
    ')
```

Use `check = FALSE` to disable checking of consistent results.

---
### Microbenchmarking &mdash; `bench::mark()`

**Example: benchmark against parameter grid**

```{r, results='hide', cache=T}
set.seed(42)

create_df <- function(rows, cols) {
  as.data.frame(setNames(
    replicate(cols, runif(rows, 1, 1000), simplify = FALSE),
    rep_len(c("x", letters), cols)))
}

results <- bench::press(
  rows = c(10000, 100000),
  cols = c(10, 100),
  {
    dat <- create_df(rows, cols)
    bench::mark(
      min_iterations = 100,
      bracket = dat[dat$x > 500, ],
      which = dat[which(dat$x > 500), ],
      subset = subset(dat, x > 500)
    )
  }
)
```

---
### Microbenchmarking &mdash; `bench::mark()`

**Example: benchmark against parameter grid**

.small[

```{r, echo=F}
cat('
#> # A tibble: 12 x 12
#>    expression   rows  cols      min     mean   median      max `itr/sec` mem_alloc  n_gc n_itr total_time
#>    <chr>       <dbl> <dbl> <bch:tm> <bch:tm> <bch:tm> <bch:tm>     <dbl> <bch:byt> <dbl> <int>   <bch:tm>
#>  1 bracket     10000    10    830µs   1.06ms 987.08µs   2.29ms    940.      1.17MB    18   304   323.47ms
#>  2 which       10000    10 447.96µs 652.94µs 564.73µs    1.6ms   1532.    827.04KB    21   551   359.77ms
#>  3 subset      10000    10 906.91µs   1.15ms   1.04ms   2.27ms    866.      1.28MB    21   320   369.44ms
#>  4 bracket    100000    10  14.96ms  17.34ms  17.39ms  19.95ms     57.7    11.54MB    46    54   936.47ms
#>  5 which      100000    10   9.09ms  11.24ms  11.04ms  15.25ms     89.0     7.91MB    32    68   764.24ms
#>  6 subset     100000    10  14.76ms  16.86ms  16.07ms  20.74ms     59.3    12.68MB    46    54   910.46ms
#>  7 bracket     10000   100   7.19ms   9.16ms   8.76ms     13ms    109.      9.71MB    34    66   604.84ms
#>  8 which       10000   100   2.74ms   4.17ms   3.98ms   8.17ms    240.      5.91MB    19    81   338.03ms
#>  9 subset      10000   100   7.19ms   9.63ms   9.46ms  12.54ms    104.      9.84MB    35    65   626.03ms
#> 10 bracket    100000   100 100.19ms  111.1ms 111.08ms 121.63ms      9.00   97.47MB    83    21      2.33s
#> 11 which      100000   100  54.19ms  59.62ms  59.36ms  65.77ms     16.8    59.51MB    36    64      3.82s
#> 12 subset     100000   100 103.36ms 113.58ms 111.83ms    134ms      8.80   98.62MB    84    16      1.82s
')
```

]

`ggplot2::autoplot()` automatically generates a facet plot for `results`.

```{r, eval=F}
plot(results)
```

---
### Microbenchmarking &mdash; `bench::mark()`

**Example: benchmark against parameter grid**

```{r, echo=F, fig.width = 13, fig.height=8.5}
plot(results)
```

---
### Microbenchmarking &mdash; Exercises

1. Instead of using `bench::mark()`, you could use the built-in function `system.time()` which is, however, much less precise, so you’ll need to repeat each operation many times with a loop, and then divide to find the average time of each operation, as in the code below.
    
    ```
    n <- 1e6
    system.time(for (i in 1:n) sqrt(x)) / n
    system.time(for (i in 1:n) x ^ 0.5) / n
    ```

  How do the estimates from `system.time()` compare to those from `bench::mark()`? Why are they different?

2. Here are two other ways to compute the square root of a vector. Which do you think will be fastest? Which will be slowest? Use microbenchmarking to test your answers.

    ```
    x ^ (1 / 2)
    exp(log(x) / 2)
    ```
---
class: inverse, left, top
background-image: url(img/road.jpg)
background-size: cover
### (Why) is R slow?

---
### (Why) is R slow?

Think of R as both the definition of a language and its implementation.

**`R` language**

- The R language defines meaning of code statements and how they work (*very abstract*) 

- R is an extremly dynamic language, i.e., you have *a lot* freedom in modifying objects after they have been created

- This dynamism is comfortable because is allows you to iterate your code and alter objects &mdash; there's no need to start from scratch when something doesn't work out!

`r emo::ji('lightning')` Changes for improving speed whithout breaking existing code are problematic. 

---
### (Why) is R slow? &mdash; Slow Code Interpretation

... but:

`R` is an interpreted language. Its dynamism causes code interpretation to be relatively time consuming.

**Example**

```{r, echo=TRUE, rx =T}
x <- 0L
for (i in 1:1e6) {
  x <- x + 1
}
```

In the above example, the interpreter cannot predict that the loop always adds `1` to an integer `x`. `R` needs to look for the right `+` method (the method for adding two doubles) in *every* iteration of the loop!

---
### (Why) is R slow?

**Implementation**

- Processes R code and computes results; commonly base R (*GNU-R*) from [cran.r-project.org](https://cran.r-project.org/src/base/R-3/)

- R (written in *Fortran*, *R*, and *C*) is more than 20 years old was not indented for super fast computations

- `r emo::ji('bolt')` tweaking for speed improvements is easier (done by R-core team) but not feasible for end users like us. <br><br> Some alternatives adress specific issues:

  - "pretty quick R" [pqR](http://www.pqr-project.org/) (parallelization of core functions)
  
  - [Microsoft R Open](https://mran.microsoft.com/open) (some fast extensions for machine learning)


---
### (Why) is R slow? &mdash; Name Lookup with Mutuable Environments

**Lexical Scoping in a Nutshell:**

*"Values of variables are searched for in the environment the function belongs to."*


- If a value is not found in the environment in which a function was defined, search steps-up to the *parent environment*

- This continues down the sequence of parent environments until the top-level environment (usually the *global environment* or a package namespace) is reached

- After the top-level environment, the search continues down the *search list* until we hit the *empty environment*.

---
### (Why) is R slow? &mdash; Name Lookup with Mutuable Environments

**Example: have you seen z?**

Interpreter asks: which environment does the value of `z` come from?

```{r, eval=FALSE}
f <- function(x, y) {
  x + y / z
}
```

```{r}
# print search list
search()
```

---
### (Why) is R slow? &mdash; Name Lookup with Mutuable Environments

**Example: have you seen z?**

Interpreter asks: which environment does the value of `z` come from?

```{r, eval=FALSE}
z <- 1                 # global environment

f <- function() {      # f() is parent to g()
  print(z)
  g <- function() {
    z <- 3
    print(z)
  }
  z <- 2
  print(z)
  g() 
}
f()
```

Name lookup is done every time we call `print(z)`!

---
### (Why) is R slow? &mdash; Lookup with Mutuable Environments

Even more problematic: most operations are lexically scoped function calls. This includes `+` and `-` but also (sometimes "racklessly" used) *operators* like `(` and `{`.

**Example: excessive usage of parenthesis.**

(a first example of poorly written code)

```{r, cache=T}
g <- function(x) x = (1/(1 + x))
h <- function(x) x = ((1/(1 + x)))
i <- function(x) x = (((1/(1 + x))))

x <- sample(1:100, 100, replace = TRUE)

bench::mark(g(x), h(x), i(x))
```

---
### (Why) is R slow? &mdash; Lookup with Mutuable Environments

**Example: function calls in nested environments**


```{r, cache=T}
f <- function(x, y) {
  (x + y) ^ 2
}

random_env <- function(parent = globalenv()) {
  letter_list <- setNames(as.list(runif(26)), LETTERS)
  list2env(letter_list, envir = new.env(parent = parent))
}

set_env <- function(f, e) {
  environment(f) <- e
  f
}

f2 <- set_env(f, random_env())
f3 <- set_env(f, random_env(environment(f2)))
f4 <- set_env(f, random_env(environment(f3)))

```

---
### (Why) is R slow? &mdash; Lookup with Mutuable Environments

**Example: function calls in nested environments &mdash; ctd.**

```{r, warning=F, message=F, cache=T}
bench::mark(f(1, 2), f2(1, 2), f3(1, 2), f4(1, 2))
```

Each additional environment between `f()` and the global environment where `+` and `^` are defined increases computation time.

---
### (Why) is R slow? &mdash; Lazy Evaluation Overhead

R function arguments are lazy --- they are only evaluated when actually needed. An unevaluated argument is called *promise* and consists of

  1. an expression
    
  2. a corresponding environment
    
  3. a value (if the expression was evaluated)

**Example: lazy evaluation**

```{r, eval=F}
f1 <- function(a) {force(a); NULL} # why not simply write 'a'?
f1(stop("My dog speaks chinese"))
```

vs.

```{r, eval=F}
f1 <- function(a) NULL
f1(stop("My dog speaks chinese"))
```

---
### (Why) is R slow? &mdash; Lazy Evaluation Overhead

Promises are very convnient but should be avoided if speed is crucial.

**Example: lazy evaluation**

```{r}
f1 <- function(a) NULL
f2 <- function(a = 1, b = 2, c = 4, d = 4, e = 5) NULL
bench::mark(f1(), f2())
```

Arguments trigger promises each time the function is *called*. Superflous arguments thus lead to avoidable overhead.

---
### (Why) is R slow? &mdash; Summary


- R is not slow *per se* &mdash; but it is slow compared to other languages:

    Speed isn't its strongest suit but accessability and compatibility are. R was designed to make life easier for you, not for your computer!

    More technically: R is an easy-to-use high level programming language. It provides a flexible and extensible toolkit for data analysis and statistics.

- We are (mostly) happy to accept the slower speed for the time saved from not having to reinvent the wheel each time we want to implement a new function that, e.g., computes a test statistic.

    (meanwhile there are `r nrow(available.packages(repos = "http://cran.us.r-project.org"))` packages available on [CRAN](https://cran.r-project.org/) with many useful functions waiting to be discovered by you!)

- We cannot overcome the circumstances described in this section. However, there are a few things to keep in mind when you want to write high performance code. We'll discuss these in the next chapter.

---
class: inverse, left, middle
background-image: url(img/road.jpg)
background-size: cover
### Improving Performance

*We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%. A good programmer will not be lulled into complacency by such reasoning, he will be wise to look carefully at the critical code; but only after that code has been identified.*

— Donald Knuth

---
### Improving Performance &mdash; Overview

Once profiling has revealed a bottleneck, we need to make it faster. In the following we will discuss some techniques that are broadly useful:

1. **Look for existing solutions.**

    Searching google can save you lots of time. The benefit of finding a faster (but possibly suboptimal) solution on your own may be small.

2. **Do as little as possible. Be precise.**

    Using optimized functions tailored for specific tasks often makes a big difference.

3. **Vectorise your code.**

    This often relates to avoiding `for()`-loops and the associated inefficiencies.

4. **Parallelize (if possible).**

    Using multiple CPU cores in parallel is enormously helpful when the computation involves a large number of tasks that may be solved independently.

---
### 1. Look for Existing Solutions

There's a good chance that someone has already tackled the same problem.

- Find out if there is a [Cran Task View](https://cran.rstudio.com/web/views/) related to your problem and search the packages listed there

- Limit your search to packages that depend on the Rcpp package (and thus likely implement high-performant C++ code). This is easily done by checking reverse dependencies of [Rcpp](https://cran.r-project.org/web/packages/Rcpp/).

- Check if a question related to your problem has been asked on [stackoverflow](https://stackoverflow.com/). Narrow the search by using suitable tags, e.g., `[r]`, `[performance]`.

- Google. For R-related results, use [rseek](https://rseek.org/).

**Record all solutions that you find not just those that immediately appear to be faster!**

- Some solutions might be initially slower but are are easier to optimize and thus end up being faster. 

- Sometimes combining the fastest parts from different approaches is helpful. 

---
### Improving Performance &mdash; Golden Rule

Before we continue, we introduce a rule we have already been implicitly following &mdash; the **golden rule of R programming**:

  ***Access the underlying C/Fortran routines as quickly as possible; the fewer functions calls required to achieve this, the better.***

  ***(Lovelace and Gillespie, 2016)***

![:image 40%](img/goldenR.png)

The techniques discussed next follow this paradigm. 

If this is not enough, we still may rewrite (some of) the code in C++ using the Rcpp package (discussed in the next chapter).

---
### 2. Do as Little as Possible

If you cannot find existing solutions, start by reducing your code to the bare essentails.

**Example: coercion of inputs / robustness checks**

`apply()` accepts various inputs and outputs which requires coercion (which is slow).

```{r, cache = T}
X <- matrix(1:1000, ncol = 10)
Y <- as.data.frame(X)

bench::mark(
  apply(X, 1, sum),
  apply(Y, 1, sum)
)
```

---
### 2. Do as Little as Possible

A function is faster if it has less to do &mdash; obvious but often neglected!

Use a function tailored to a more specific type of input or output, or a more specific problem.

**Example: row sums &mdash; `rowSums()` vs. `apply()`**

`apply()` has a much longer call stack than `rowSums()` which is much more specific. 

```{r, cache = T}
bench::mark(
  rowSums(X),
  apply(X, 1, sum)
)
```

---
### 2. Do as Little as Possible

**Example: search vector for entry**

Testing equality is faster than testing inclusion in a set.

```{r, cache=T}
x <- 1:100

bench::mark(
  any(x == 10),
  10 %in% x
)
```

---
### 2. Do as Little as Possible

**Example: Linear Regression &mdash; computation of $SE(\widehat\beta)$**

`a()` is what we teach undergraduates which is totally fine &mdash; except if you want (only) $SE(\widehat\beta)$ and fast.

`b()` is rather focussed on the essentials.

```{r, cache=T}
set.seed(1)
X <- matrix(rnorm(100), ncol = 1)
Y <- X + rnorm(100)

a <- function() {
  coefficients(summary(lm(Y ~ X - 1)))[1, 2]  
}

b <- function() {
  fit <- lm.fit(X, Y)
  c(
    sqrt(1/(length(X)-1) * sum(fit$residuals^2) * solve(t(X) %*% X))
    )
}
```

---
### 2. Do as Little as Possible

**Example: Linear Regression &mdash; computation of $SE(\widehat\beta)$**

Let's compare both approaches in a microbenchmark.

```{r, cache = T}
bench::mark(
  a(),
  b()
)
```

The difference is indeed huge.

---
### 2. Do as Little as Possible

Be as explicit as possible.

**Example: method dispatch**

```{r}
x <- runif(1e2)

bench::mark(
  mean(x),
  mean.default(x)
)
```

---
### 2. Do as Little as Possible

Benchmark against alternatives that rely on primitive functions.

**Example: primitives are faster**

```{r}
bench::mark(
  mean.default(x),
  sum(x)/length(x)
)
```

---
### 2. Do as Little as Possible &mdash; Exercises

1\. Can you come up with an even faster implementation of `b()` in the linear regression example?

2\. `rowSums2()` is an alternative implementation of `rowSums()`. Is it faster for the input `df`? Why?

```{r, eval=F}
rowSums2 <- function(df) {
out <- df[[1L]]
if (ncol(df) == 1) return(out)
    
  for (i in 2:ncol(df)) {
    out <- out + df[[i]]
  }
  out
}
    
df <- as.data.frame(
  replicate(1e3, sample(100, 1e4, replace = TRUE))
)
```

3\. What’s the difference between `rowSums()` and `.rowSums()`?

---
### 2. Do as Little as Possible &mdash; Exercises

4\. Write a faster version of `chisq.test()` that only computes the chi-square test statistic when the input is two numeric vectors with no missing values. Start by coding from the [definition](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test).

---
### 2. Do as Little as Possible &mdash; Case Study

Imagine you want to compute the bootstrap distribution of a sample correlation using `cor_df()` and the data in the example below. Given that you want to run this many times, how can you make this code faster? 

(Hint: the function has three components that you can speed up.)

```{r, eval=F}
n <- 1e6
df <- data.frame(a = rnorm(n), b = rnorm(n))
    
cor_df <- function(df, n) {
  i <- sample(seq(n), n, replace = TRUE)
  cor(df[i, , drop = FALSE])[2, 1]
}
```

---
### 3. Vectorize your code

**What is vectorization?** 

- Vectorization is the process of converting an algorithm from operating on a single value at a time to operating on a **set of values** (like a vector) at one time.

- It makes problems simpler: code that operates on vectors instead of single entries of an array is often less complex to write.

**Why is it efficient?** 

- Your computer is designed to run vectorized operations: a vectorized function may run multiple operations from a single instruction which is faster than sending individual instructions for each operation.  

---
### 3. Vectorize your code

**Why is vectorization efficient? &mdash; ctd.** 

Many languages (including R) work on arrays that are stored in [column-major order](https://en.m.wikipedia.org/wiki/Row-_and_column-major_order) in the memory.

![:image 60%](img/rowcolumnarrays.jpg)

Disregarding these patterns by writing code which operates on $1\times1$ vectors thus means 'fighting the language'.

---
### 3. Vectorize your code

**Why is vectorization more efficient? &mdash; ctd. **

**(less related to R itself but to what your CPU does)**

**Example: vector addition**

$$\begin{pmatrix} 1 \\ 2\\ 3 \end{pmatrix}+\begin{pmatrix} 4 \\ 5\\ 6 \end{pmatrix} = \begin{pmatrix} 5 \\ 7\\ 9 \end{pmatrix}$$

- **Slow:** three instructions, three operations

    - *add $\ 1$ and $\ 4$*
    - *add $\ 2$ and $\ 5$*
    - *add $\ 3$ and $\ 6$*

- **Fast:** one instruction, one vectorized operation:

    *add $\begin{pmatrix} 1 \ 2 \  3 \end{pmatrix}'$ and $\begin{pmatrix} 4 \ 5 \  6 \end{pmatrix}'$*

    The three additions are effectively done *in parallel*.


---
### 3. Vectorize your code

**What does it mean to write 'vectorized' code in R?**

Remember that there are no 'real' scalars in R. Everything that looks like a scalar is actually a $1\times1$ vector.

![:image 30%](img/atomic_vectors.png)

```{r}
# otherwise this shouldn't work:
1[1]
```

Scalar operations thus operate on vector *elements* which (often) is needlessly cumbersome. 

---
### 3. Vectorize your code

**What does it mean to write 'vectorized' code in R?**

- **Do not torture the interpreter**

    Vectorization reduces the amount of intepreting R has to do: Validating that `x <- 1L` and `y <- 1:100L` are of type `integer` is equally expensive. Checking that each element of `y` is an integer is not!   

- **Use functions from base R that work on vectors**

    Vectorization may avoid loops in R. Loops in many 'vectorized' R functions are carried out in C and thus are much faster. 

    The following functions are prominent examples:

    `rowSums()`, `colSums()`, `rowMeans()`, `colMeans()`, `cumsum()`, `diff()`

- **Use matrix algebra**

    Most matrix operations that involve loops are executed by highly optimized external Fortran and C libraries. See, e.g., [BLAS](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms).

---
### 3. Vectorize your code &mdash; Tips and Tricks

**Are `*apply()` functions faster than `for ()`?**



---
### 3. Vectorize your code
  
- Avoid `ifelse()` &mdash; despite being a vectorized version of the standard control flow `'if(condition) if_yes else if_no'` it is slower
    
---
### 3. Vectorize your code &mdash; Exercises

1. Compare the speed of `apply(X, 1, sum)` with the vectorized `rowSums(X)` for varying sizes of the square matrix `X` using `bench::mark()`. Consider the dimensions `1`, `1e1`, `1e2`, `1e3`, `0.5e4` and `1e5`. Visualize the results using a violin plot.

2. 

    (a) How can you vectorize the computation of a weighted sum?

    (b) How can you use `crossprod()` to compute that same sum? 

    (c) How much faster are the approaches in (a) and (b) compared to the 'naive' approach `sum(x * w)`?

3. 

---
### References

Wickham, H. (2019). Advanced R. 2nd Edition. Taylor & Francis, CRC Press.

Peng, Roger D. (2016), R Programming for Data Science. The bookdown Archive.

---
class: inverse, left, top

background-image: url(img/road.jpg)
background-size: cover

# Speeding things up using Rcpp

---
class: inverse, left, top

background-image: url(img/road.jpg)
background-size: cover

# Microbenchmarking



---
### xaringan

```terminal
josh@brick ~/repos/aha $ git log -2
<span style="color:olive;">commit 36b0a3af174e204c8d0a7a993ad467cd7be39bca</span>
Author: Ziz <zizsdl@googlemail.com>
Date:   Fri Aug 3 10:29:43 2012 +0200
    Small version changes, make clean, merging, etc.
...
```

---
class: inverse, center, middle

# Get Started

---

# Hello World

Install the **xaringan** package from [Github](https://github.com/yihui/xaringan):

```{r eval=FALSE, tidy=FALSE}
devtools::install_github("yihui/xaringan")
```

--

You are recommended to use the [RStudio IDE](https://www.rstudio.com/products/rstudio/), but you do not have to.

- Create a new R Markdown document from the menu `File -> New File -> R Markdown -> From Template -> Ninja Presentation`;<sup>1</sup>

--

- Click the `Knit` button to compile it;

--

- or use the [RStudio Addin](https://rstudio.github.io/rstudioaddins/)<sup>2</sup> "Infinite Moon Reader" to live preview the slides (every time you update and save the Rmd document, the slides will be automatically reloaded in RStudio Viewer.

.footnote[
[1] 中文用户请看[这份教程](http://slides.yihui.name/xaringan/zh-CN.html)

[2] See [#2](https://github.com/yihui/xaringan/issues/2) if you do not see the template or addin in RStudio.
]

---
background-image: url(`r xaringan:::karl`)
background-position: 50% 50%
class: center, bottom, inverse

# You only live once!

---

# Hello Ninja

As a presentation ninja, you certainly should not be satisfied by the "Hello World" example. You need to understand more about two things:

1. The [remark.js](https://remarkjs.com) library;

1. The **xaringan** package;

Basically **xaringan** injected the chakra of R Markdown (minus Pandoc) into **remark.js**. The slides are rendered by remark.js in the web browser, and the Markdown source needed by remark.js is generated from R Markdown (**knitr**).

---

# remark.js

You can see an introduction of remark.js from [its homepage](https://remarkjs.com). You should read the [remark.js Wiki](https://github.com/gnab/remark/wiki) at least once to know how to

- create a new slide (Markdown syntax<sup>*</sup> and slide properties);

- format a slide (e.g. text alignment);

- configure the slideshow;

- and use the presentation (keyboard shortcuts).

It is important to be familiar with remark.js before you can understand the options in **xaringan**.

.footnote[[*] It is different with Pandoc's Markdown! It is limited but should be enough for presentation purposes. Come on... You do not need a slide for the Table of Contents! Well, the Markdown support in remark.js [may be improved](https://github.com/gnab/remark/issues/142) in the future.]

---
background-image: url(`r xaringan:::karl`)
background-size: cover
class: center, bottom, inverse

# I was so happy to have discovered remark.js!

---
class: inverse, middle, center

# Using xaringan

---

# xaringan

Provides an R Markdown output format `xaringan::moon_reader` as a wrapper for remark.js, and you can use it in the YAML metadata, e.g.

```yaml
---
title: "A Cool Presentation"
output:
  xaringan::moon_reader
    yolo: true
    nature:
      autoplay: 30000
---
```

See the help page `?xaringan::moon_reader` for all possible options that you can use.

---

# remark.js vs xaringan

Some differences between using remark.js (left) and using **xaringan** (right):

.pull-left[
1. Start with a boilerplate HTML file;

1. Plain Markdown;

1. Write JavaScript to autoplay slides;

1. Manually configure MathJax;

1. Highlight code with `*`;

1. Edit Markdown source and refresh browser to see updated slides;
]

.pull-right[
1. Start with an R Markdown document;

1. R Markdown (can embed R/other code chunks);

1. Provide an option `autoplay`;

1. MathJax just works;<sup>*</sup>

1. Highlight code with `{{}}`;

1. The RStudio addin "Infinite Moon Reader" automatically refreshes slides on changes;
]

.footnote[[*] Not really. See next page.]

---

# Math Expressions

You can write LaTeX math expressions inside a pair of dollar signs, e.g. &#36;\alpha+\beta$ renders $\alpha+\beta$. You can use the display style with double dollar signs:

```
$$\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i$$
```

$$\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i$$

Limitations:

1. The source code of a LaTeX math expression must be in one line, unless it is inside a pair of double dollar signs, in which case the starting `$$` must appear in the very beginning of a line, followed immediately by a non-space character, and the ending `$$` must be at the end of a line, led by a non-space character;

1. There should not be spaces after the opening `$` or before the closing `$`.

1. Math does not work on the title slide (see [#61](https://github.com/yihui/xaringan/issues/61) for a workaround).

---

# R Code

```{r comment='#'}
# a boring regression
fit = lm(dist ~ 1 + speed, data = cars)
coef(summary(fit))
dojutsu = c('地爆天星', '天照', '加具土命', '神威', '須佐能乎', '無限月読')
grep('天', dojutsu, value = TRUE)
```

---

# R Plots

```{r cars, fig.height=4, dev='svg'}
par(mar = c(4, 4, 1, .1))
plot(cars, pch = 19, col = 'darkgray', las = 1)
abline(fit, lwd = 2)
```

---

# Tables

If you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g.,

```{r}
knitr::kable(head(iris), format = 'html')
```

---

# HTML Widgets

I have not thoroughly tested HTML widgets against **xaringan**. Some may work well, and some may not. It is a little tricky.

Similarly, the Shiny mode (`runtime: shiny`) does not work. I might get these issues fixed in the future, but these are not of high priority to me. I never turn my presentation into a Shiny app. When I need to demonstrate more complicated examples, I just launch them separately. It is convenient to share slides with other people when they are plain HTML/JS applications.

See the next page for two HTML widgets.

---

```{r out.width='100%', fig.height=6, eval=require('leaflet')}
library(leaflet)
leaflet() %>% addTiles() %>% setView(-93.65, 42.0285, zoom = 17)
```

---

```{r eval=require('DT'), tidy=FALSE}
DT::datatable(
  head(iris, 10),
  fillContainer = FALSE, options = list(pageLength = 8)
)
```

---

# Some Tips

- When you use the "Infinite Moon Reader" addin in RStudio, your R session will be blocked by default. You can click the red button on the right of the console to stop serving the slides, or use the _daemonized_ mode so that it does not block your R session. To do the latter, you can set the option

    ```r
    options(servr.daemon = TRUE)
    ```
    
    in your current R session, or in `~/.Rprofile` so that it is applied to all future R sessions. I do the latter by myself.
    
    To know more about the web server, see the [**servr**](https://github.com/yihui/servr) package.

--

- Do not forget to try the `yolo` option of `xaringan::moon_reader`.

    ```yaml
    output:
      xaringan::moon_reader:
        yolo: true
    ```

---

# Some Tips

- Slides can be automatically played if you set the `autoplay` option under `nature`, e.g. go to the next slide every 30 seconds in a lightning talk:

    ```yaml
    output:
      xaringan::moon_reader:
        nature:
          autoplay: 30000
    ```

--

- A countdown timer can be added to every page of the slides using the `countdown` option under `nature`, e.g. if you want to spend one minute on every page when you give the talk, you can set:

    ```yaml
    output:
      xaringan::moon_reader:
        nature:
          countdown: 60000
    ```

    Then you will see a timer counting down from `01:00`, to `00:59`, `00:58`, ... When the time is out, the timer will continue but the time turns red.

---

# Some Tips

- There are several ways to build incremental slides. See [this presentation](https://slides.yihui.name/xaringan/incremental.html) for examples.

- The option `highlightLines: true` of `nature` will highlight code lines that start with `*`, or are wrapped in `{{ }}`, or have trailing comments `#<<`;

    ```yaml
    output:
      xaringan::moon_reader:
        nature:
          highlightLines: true
    ```

    See examples on the next page.

---

# Some Tips


.pull-left[
An example using a leading `*`:

    ```r
    if (TRUE) {
    ** message("Very important!")
    }
    ```
Output:
```r
if (TRUE) {
* message("Very important!")
}
```

This is invalid R code, so it is a plain fenced code block that is not executed.
]

.pull-right[
An example using `{{}}`:

    `r ''````{r tidy=FALSE}
    if (TRUE) {
    *{{ message("Very important!") }}
    }
    ```
Output:
```{r tidy=FALSE}
if (TRUE) {
{{ message("Very important!") }}
}
```

It is valid R code so you can run it. Note that `{{}}` can wrap an R expression of multiple lines.
]

---

# Some Tips

An example of using the trailing comment `#<<` to highlight lines:

````markdown
`r ''````{r tidy=FALSE}
library(ggplot2)
ggplot(mtcars) + 
  aes(mpg, disp) + 
  geom_point() +   #<<
  geom_smooth()    #<<
```
````

Output:

```{r tidy=FALSE, eval=FALSE}
library(ggplot2)
ggplot(mtcars) + 
  aes(mpg, disp) + 
  geom_point() +   #<<
  geom_smooth()    #<<
```

---

# Some Tips

- To make slides work offline, you need to download a copy of remark.js in advance, because **xaringan** uses the online version by default (see the help page `?xaringan::moon_reader`).

- You can use `xaringan::summon_remark()` to download the latest or a specified version of remark.js. By default, it is downloaded to `libs/remark-latest.min.js`.

- Then change the `chakra` option in YAML to point to this file, e.g.

    ```yaml
    output:
      xaringan::moon_reader:
        chakra: libs/remark-latest.min.js
    ```

- If you used Google fonts in slides (the default theme uses _Yanone Kaffeesatz_, _Droid Serif_, and _Source Code Pro_), they won't work offline unless you download or install them locally. The Heroku app [google-webfonts-helper](https://google-webfonts-helper.herokuapp.com/fonts) can help you download fonts and generate the necessary CSS.

---

# Macros

- remark.js [allows users to define custom macros](https://github.com/yihui/xaringan/issues/80) (JS functions) that can be applied to Markdown text using the syntax `![:macroName arg1, arg2, ...]` or `![:macroName arg1, arg2, ...](this)`. For example, before remark.js initializes the slides, you can define a macro named `scale`:

    ```js
    remark.macros.scale = function (percentage) {
      var url = this;
      return '<img src="' + url + '" style="width: ' + percentage + '" />';
    };
    ```

    Then the Markdown text

    ```markdown
    ![:scale 50%](image.jpg)
    ```

    will be translated to
    
    ```html
    <img src="image.jpg" style="width: 50%" />
    ```

---

# Macros (continued)

- To insert macros in **xaringan** slides, you can use the option `beforeInit` under the option `nature`, e.g.,

    ```yaml
    output:
      xaringan::moon_reader:
        nature:
          beforeInit: "macros.js"
    ```

    You save your remark.js macros in the file `macros.js`.

- The `beforeInit` option can be used to insert arbitrary JS code before `remark.create()`. Inserting macros is just one of its possible applications.

---

# CSS

Among all options in `xaringan::moon_reader`, the most challenging but perhaps also the most rewarding one is `css`, because it allows you to customize the appearance of your slides using any CSS rules or hacks you know.

You can see the default CSS file [here](https://github.com/yihui/xaringan/blob/master/inst/rmarkdown/templates/xaringan/resources/default.css). You can completely replace it with your own CSS files, or define new rules to override the default. See the help page `?xaringan::moon_reader` for more information.

---

# CSS

For example, suppose you want to change the font for code from the default "Source Code Pro" to "Ubuntu Mono". You can create a CSS file named, say, `ubuntu-mono.css`:

```css
@import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

.remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
```

Then set the `css` option in the YAML metadata:

```yaml
output:
  xaringan::moon_reader:
    css: ["default", "ubuntu-mono.css"]
```

Here I assume `ubuntu-mono.css` is under the same directory as your Rmd.

See [yihui/xaringan#83](https://github.com/yihui/xaringan/issues/83) for an example of using the [Fira Code](https://github.com/tonsky/FiraCode) font, which supports ligatures in program code.

---

# Themes

Don't want to learn CSS? Okay, you can use some user-contributed themes. A theme typically consists of two CSS files `foo.css` and `foo-fonts.css`, where `foo` is the theme name. Below are some existing themes:

```{r}
names(xaringan:::list_css())
```

To use a theme, you can specify the `css` option as an array of CSS filenames (without the `.css` extensions), e.g.,

```yaml
output:
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts]
```

If you want to contribute a theme to **xaringan**, please read [this blog post](https://yihui.name/en/2017/10/xaringan-themes).

---
class: inverse, middle, center
background-image: url(https://upload.wikimedia.org/wikipedia/commons/3/39/Naruto_Shiki_Fujin.svg)
background-size: contain

# Naruto

---
background-image: url(https://upload.wikimedia.org/wikipedia/commons/b/be/Sharingan_triple.svg)
background-size: 100px
background-position: 90% 8%

# Sharingan

The R package name **xaringan** was derived<sup>1</sup> from **Sharingan**, a dōjutsu in the Japanese anime _Naruto_ with two abilities:

- the "Eye of Insight"

- the "Eye of Hypnotism"

I think a presentation is basically a way to communicate insights to the audience, and a great presentation may even "hypnotize" the audience.<sup>2,3</sup>

.footnote[
[1] In Chinese, the pronounciation of _X_ is _Sh_ /ʃ/ (as in _shrimp_). Now you should have a better idea of how to pronounce my last name _Xie_.

[2] By comparison, bad presentations only put the audience to sleep.

[3] Personally I find that setting background images for slides is a killer feature of remark.js. It is an effective way to bring visual impact into your presentations.
]

---

# Naruto terminology

The **xaringan** package borrowed a few terms from Naruto, such as

- [Sharingan](http://naruto.wikia.com/wiki/Sharingan) (写輪眼; the package name)

- The [moon reader](http://naruto.wikia.com/wiki/Moon_Reader) (月読; an attractive R Markdown output format)

- [Chakra](http://naruto.wikia.com/wiki/Chakra) (查克拉; the path to the remark.js library, which is the power to drive the presentation)

- [Nature transformation](http://naruto.wikia.com/wiki/Nature_Transformation) (性質変化; transform the chakra by setting different options)

- The [infinite moon reader](http://naruto.wikia.com/wiki/Infinite_Tsukuyomi) (無限月読; start a local web server to continuously serve your slides)

- The [summoning technique](http://naruto.wikia.com/wiki/Summoning_Technique) (download remark.js from the web)

You can click the links to know more about them if you want. The jutsu "Moon Reader" may seem a little evil, but that does not mean your slides are evil.

---

class: center

# Hand seals (印)

Press `h` or `?` to see the possible ninjutsu you can use in remark.js.

![](https://upload.wikimedia.org/wikipedia/commons/7/7e/Mudra-Naruto-KageBunshin.svg)

---

class: center, middle

# Thanks!

Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).

The chakra comes from [remark.js](https://remarkjs.com), [**knitr**](http://yihui.name/knitr), and [R Markdown](https://rmarkdown.rstudio.com).



